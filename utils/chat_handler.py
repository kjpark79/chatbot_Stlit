import openai
import os
import json
from utils.vector_store import VectorStore
from typing import List, Dict, Tuple

class ChatHandler:
    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        openai.api_key = os.getenv('OPENAI_API_KEY')
        self.model = "gpt-4o-mini"
        self.conversation_sessions = {}
    
    def get_response(self, user_message: str, session_id: str = "default") -> Tuple[str, List[str]]:
        if session_id not in self.conversation_sessions:
            self.conversation_sessions[session_id] = []
        
        relevant_docs = self.vector_store.search(user_message, n_results=8)
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±ì„ ìœ„í•œ ë¬¸ì„œ ì •ë³´
        context = ""
        doc_metadata = {}
        
        for i, doc in enumerate(relevant_docs):
            source_name = doc['metadata']['source']
            
            # ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚° (ìƒìœ„ ê²°ê³¼ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            relevance_score = (len(relevant_docs) - i) / len(relevant_docs)
            
            # ë¬¸ì„œë³„ ê´€ë ¨ë„ ì ìˆ˜ ëˆ„ì 
            if source_name not in doc_metadata:
                doc_metadata[source_name] = {'score': 0, 'content': []}
            doc_metadata[source_name]['score'] += relevance_score
            doc_metadata[source_name]['content'].append(doc['document'])
            
            context += f"ðŸ” **ì¶œì²˜: {source_name}** (ê´€ë ¨ë„: {relevance_score:.2f})\n"
            context += f"ðŸ“ ë‚´ìš©: {doc['document']}\n\n"
        
        system_prompt = """ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ë¬¸ì„œë¥¼ ê¼¼ê¼¼ížˆ ì‚´íŽ´ë³´ê³  ì¹œê·¼í•˜ê²Œ ë„ì™€ë“œë¦¬ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤. ðŸ˜Š

ì œê°€ ë„ì™€ë“œë¦´ ë•Œ ì´ëŸ° ì ë“¤ì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•´ìš”:
- ì—…ë¡œë“œí•˜ì‹  ë¬¸ì„œ ë‚´ìš©ì—ì„œ ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ê³¼ ì •í™•ížˆ ì¼ì¹˜í•˜ëŠ” ë¶€ë¶„ì„ ìš°ì„ ì ìœ¼ë¡œ ì°¾ì•„ì„œ ë‹µë³€ë“œë ¤ìš”
- ë¬¸ì„œì—ì„œ ì°¾ì€ êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ë“œë ¤ìš”  
- ì´ì „ ëŒ€í™” ë‚´ìš©ë„ í•¨ê»˜ ê³ ë ¤í•´ì„œ ë§¥ë½ì— ë§žëŠ” ë‹µë³€ì„ ë“œë ¤ìš”
- ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë§íˆ¬ë¡œ ì„¤ëª…í•´ë“œë ¤ìš”
- ë¶€ì—°ì„¤ëª…ì€ ìžì œí•˜ê³  ì›ëž˜ ë¬¸ì„œì˜ ë‚´ìš©ì´ ìµœëŒ€í•œ ì •í™•í•˜ê²Œ ì „ë‹¬ë˜ë„ë¡ í•´ìš”
- ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ë“œë ¤ìš”

ë§Œì•½ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ ì†”ì§í•˜ê²Œ ë§ì”€ë“œë¦´ê²Œìš”. ê¶ê¸ˆí•œ ê²ƒì´ ìžˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ íŽ¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!"""
        
        messages = [{"role": "system", "content": system_prompt}]
        
        # ì´ì „ ëŒ€í™” ë‚´ì—­ ì¶”ê°€ (ìµœëŒ€ 10ê°œ í„´)
        conversation_history = self.conversation_sessions[session_id][-10:]
        for turn in conversation_history:
            messages.append({"role": "user", "content": turn["user"]})
            messages.append({"role": "assistant", "content": turn["assistant"]})
        
        user_prompt = f"""ðŸ“„ **ì—…ë¡œë“œí•˜ì‹  ë¬¸ì„œì—ì„œ ì°¾ì€ ê´€ë ¨ ë‚´ìš©:**

{context}

ðŸ’¬ **ì§ˆë¬¸:** {user_message}

ìœ„ ë¬¸ì„œ ë‚´ìš©ì—ì„œ ì§ˆë¬¸ê³¼ ì •í™•ížˆ ì¼ì¹˜í•˜ëŠ” ë¶€ë¶„ì´ ìžˆë‹¤ë©´ ê·¸ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìžì„¸ížˆ ë‹µë³€í•´ì£¼ì„¸ìš”. ë¬¸ì„œì˜ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•´ì„œ ì •í™•í•˜ê³  ì¹œê·¼í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”!"""
        
        messages.append({"role": "user", "content": user_prompt})
        
        try:
            response = openai.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=1500
            )
            
            assistant_response = response.choices[0].message.content
            
            # ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€
            self.conversation_sessions[session_id].append({
                "user": user_message,
                "assistant": assistant_response
            })
            
            # ë‹µë³€ì—ì„œ ì‹¤ì œ ì‚¬ìš©ëœ ë¬¸ì„œ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
            used_sources = set()
            
            # ê´€ë ¨ë„ ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_docs = sorted(doc_metadata.items(), key=lambda x: x[1]['score'], reverse=True)
            
            # ìƒìœ„ ê´€ë ¨ë„ ë¬¸ì„œ ì¤‘ì—ì„œ ì‹¤ì œ ë‹µë³€ì— í™œìš©ëœ ê²ƒë§Œ ì„ ë³„
            for doc_name, doc_info in sorted_docs:
                # ë‹µë³€ì— ë¬¸ì„œëª…ì´ ì§ì ‘ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if doc_name in assistant_response:
                    used_sources.add(doc_name)
                    continue
                
                # ë¬¸ì„œ ë‚´ìš©ì´ ë‹µë³€ì— ì‹¤ì§ˆì ìœ¼ë¡œ í™œìš©ë˜ì—ˆëŠ”ì§€ ë‹¤ì¤‘ ë°©ì‹ìœ¼ë¡œ í™•ì¸
                is_used = False
                for content_chunk in doc_info['content']:
                    # ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì œê±°í•œ ë²„ì „ìœ¼ë¡œ ë¹„êµ
                    clean_content = content_chunk.replace(' ', '').replace('\n', '').replace('\t', '')
                    clean_response = assistant_response.replace(' ', '').replace('\n', '').replace('\t', '')
                    
                    # ë°©ë²• 1: ì—°ì†ëœ ê¸´ í…ìŠ¤íŠ¸ ë§¤ì¹­ (30ìž ì´ìƒ)
                    for i in range(0, len(clean_content) - 30, 10):
                        snippet = clean_content[i:i+30]
                        if snippet in clean_response:
                            is_used = True
                            break
                    
                    if is_used:
                        break
                    
                    # ë°©ë²• 2: í•µì‹¬ í‚¤ì›Œë“œ ë°€ë„ ì²´í¬ (í•œêµ­ì–´ íŠ¹ì„± ê³ ë ¤)
                    content_words = [word for word in content_chunk.split() if len(word) > 1]
                    response_words = assistant_response.split()
                    
                    # ë¬¸ì„œì˜ ì£¼ìš” ë‹¨ì–´ë“¤ì´ ë‹µë³€ì— ì–¼ë§ˆë‚˜ í¬í•¨ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸
                    if len(content_words) > 0:
                        word_matches = sum(1 for word in content_words[:20] if word in assistant_response)
                        match_ratio = word_matches / min(len(content_words), 20)
                        
                        # 30% ì´ìƒ ë§¤ì¹­ë˜ë©´ ì‚¬ìš©ëœ ê²ƒìœ¼ë¡œ íŒë‹¨
                        if match_ratio > 0.3:
                            is_used = True
                            break
                
                if is_used:
                    used_sources.add(doc_name)
            
            # ì‹¤ì œ ì‚¬ìš©ëœ ë¬¸ì„œê°€ ì—†ë‹¤ë©´ ìµœìƒìœ„ ê´€ë ¨ë„ ë¬¸ì„œ 1ê°œë§Œ í¬í•¨
            if not used_sources and sorted_docs:
                used_sources.add(sorted_docs[0][0])
            
            used_sources = list(used_sources)
            
            return assistant_response, used_sources
            
        except Exception as e:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", []
    
    def clear_conversation(self, session_id: str = "default"):
        if session_id in self.conversation_sessions:
            self.conversation_sessions[session_id] = []
    
    def get_conversation_history(self, session_id: str = "default") -> List[Dict]:
        return self.conversation_sessions.get(session_id, [])